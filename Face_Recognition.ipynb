{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg\n",
    "from numpy.linalg import svd, qr, norm,  inv\n",
    "from All import unfold, fold, Mul_1, Mul_2, Mul_3\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_name_of_images = glob(\"YALE faces/yalefaces/train/*.gif\")\n",
    "list_of_expression = [list_of_name_of_images[i].split(\".\")[1] for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['centerlight',\n",
       " 'happy',\n",
       " 'leftlight',\n",
       " 'normal',\n",
       " 'rightlight',\n",
       " 'sad',\n",
       " 'sleepy',\n",
       " 'surprised',\n",
       " 'wink']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_list_of_persons = [[] for i in range(15)]\n",
    "slice = range(0, 136, 9)\n",
    "A = np.empty((77760, 9, 15))\n",
    "\n",
    "for i in range(15):\n",
    "\n",
    "    for filename in list_of_name_of_images[slice[i] : slice[i+1]]:\n",
    "        \n",
    "        image = mpimg.imread(filename)\n",
    "        array_of_list_of_persons[i].append(image.flatten(order=\"f\"))\n",
    "        \n",
    "    A[:, :, i] = np.matrix(array_of_list_of_persons[i]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 320)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpimg.imread(list_of_name_of_images[0]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold_1 = unfold(A, 1)\n",
    "unfold_2 = unfold(A, 2)\n",
    "unfold_3 = unfold(A, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute F, G, H, S, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, _, _ = svd(unfold_1, full_matrices=False)\n",
    "G, _, _ = svd(unfold_2, full_matrices=False)\n",
    "H, _, _ = svd(unfold_3, full_matrices=False)\n",
    "\n",
    "temp_1 = Mul_1(F.T, A)\n",
    "temp_2 = Mul_2(G.T, temp_1)\n",
    "S = Mul_3(H.T, temp_2)\n",
    "\n",
    "B = Mul_2(G, S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating list of Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_test_images = glob(\"YALE faces/yalefaces/test/*.gif\")\n",
    "array_list_of_test_images = [mpimg.imread(filename).flatten(order=\"f\") for filename in list_of_test_images]\n",
    "len(array_list_of_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "for i in range(1, 16):\n",
    "    for j in range(2):\n",
    "        true_label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute All Be = Qe * Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_e, _ = G.shape\n",
    "n_p, _ = H.shape\n",
    "list_of_Qe_Re = []\n",
    "\n",
    "for expression in range(n_e):\n",
    "    Q_e, R_e = qr(B[:, expression, :], mode=\"reduced\")\n",
    "    list_of_Qe_Re.append([Q_e, R_e])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(test_image, list_of_Qe_Re, list_of_prediction, tol):\n",
    "\n",
    "    z_hat = np.dot(F.T, test_image)\n",
    "\n",
    "    for Q_e, R_e in list_of_Qe_Re:\n",
    "\n",
    "        a_e = np.dot(np.dot(inv(R_e), Q_e.T), z_hat)\n",
    "\n",
    "        for person in range(n_p):\n",
    "\n",
    "            if norm(a_e - H[person, :], 2) < tol:\n",
    "\n",
    "                list_of_prediction.append(person+1)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition_without_tol(test_image, list_of_Qe_Re, list_of_prediction):\n",
    "\n",
    "    z_hat = np.dot(F.T, test_image)\n",
    "\n",
    "    list_of_distance = []\n",
    "\n",
    "    for Q_e, R_e in list_of_Qe_Re:\n",
    "\n",
    "        a_e = np.dot(np.dot(inv(R_e), Q_e.T), z_hat)\n",
    "\n",
    "        for person in range(n_p):\n",
    "\n",
    "            list_of_distance.append((norm(a_e - H[person, :], 2), person + 1))\n",
    "\n",
    "    list_of_distance = sorted(list_of_distance)\n",
    "    list_of_prediction.append(list_of_distance[0][1])\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuarcy of function with hyperparameter tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_prediction = []\n",
    "for test_image in array_list_of_test_images:\n",
    "\n",
    "    face_recognition(test_image, list_of_Qe_Re, list_of_prediction, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Face Recognition is = 80.00\n"
     ]
    }
   ],
   "source": [
    "accuracy = (np.count_nonzero((np.array(list_of_prediction) - np.array(true_label)) == 0) / 30) * 100\n",
    "print(f\"accuracy of Face Recognition is = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.50      1.00      0.67         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      0.50      0.67         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      0.50      0.67         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      1.00      0.67         2\n",
      "          15       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.82      0.80      0.77        30\n",
      "weighted avg       0.82      0.80      0.77        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mahan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mahan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mahan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.array(true_label), np.array(list_of_prediction)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuarcy of function without hyperparameter tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_prediction = []\n",
    "for test_image in array_list_of_test_images:\n",
    "\n",
    "    face_recognition_without_tol(test_image, list_of_Qe_Re, list_of_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Face Recognition is = 93.33\n"
     ]
    }
   ],
   "source": [
    "accuracy = (np.count_nonzero((np.array(list_of_prediction) - np.array(true_label)) == 0) / 30) * 100\n",
    "print(f\"accuracy of Face Recognition is = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      0.50      0.67         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.96      0.93      0.93        30\n",
      "weighted avg       0.96      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.array(true_label), np.array(list_of_prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efed56f0b669d97b5fc181f64e37a1c2251cb12ecfef5496847f2e3b9effed29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
